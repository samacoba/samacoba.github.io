---
layout: post
title: DiscoGANを使ってお米カウントの別の見方
category: blog
tags: 深層学習 ☆☆☆
---

2017年3月にDiscoGANが出てから２週間で書いた記事
[DiscoGANを使って「教師なし」でお米を数えてみる](https://qiita.com/samacoba/items/f04ed6a3a170fd97cef5)
ですが、そのあと忙しいのもあって、あまりなにもしてこなかったわけですが、そろそろまじめに取り組もうかと思って考えていたら、別の見方もあったので、メモしておきます。

機械学習をやってこなかった身としては「生成系」ってのがよくわからないものですが、
- PFN岡野原さんの[深層生成モデルによる表現学習](https://www.slideshare.net/pfi/iibmp2016-okanohara-deep-generative-models-for-representation-learning)
- 東大・理研杉山先生の[機械学習研究の現状とこれから](https://www.slideshare.net/MLSE/ss-97568525)

など、よく生成系はスゴイらしいっとは言われてて、現状次々といろんなGANが出てきているとてもホットな状況です。

とはいえ、きれいな絵を生成したからどうなのよ？ってのは素朴な疑問になるわけですが、何がうれしいかっていうと、「生成ができれば、サンプルが増やせるから少ない教師でも認識率も上がるよ」ってのがわかりやすい解釈かと思ってます。もうちょっとある気がしますが、まだ考えがまとまってないので、できたら書きたいと思います。

さて、お米DiscoGANに戻りますが、授業でEMアルゴリズムを最近ならったのもあって、白玉ランダム画像っていうのが潜在空間の物体の確率密度みたいな考え方と似ているような感じに思えたので、図にしてみるとこんな感じになりました。

![画像](/images/20180806-doc001_01.png)

DiscoGANにおけるドメインのーつが実ドメインXのお米画像で、もう一つが潜在ドメインZの白玉画像という並べ方にしてみました。DiscoGANでは両方のドメインでGANを使っているわけなので、お米DiscoGANでは実ドメインと潜在ドメインの両方でGANを使うことになります。このGANと元々DiscoGANでも使われているAutoEncoderだけで、特に教師※がなくても都合のよい潜在空間へドメイン変換できるってのは不思議な感じです。 
※ランダムを仮定するのはあるいみ教師ではありますが。

どんな潜在空間にしたらいいかは研究の余地が若干ありそうで、博士が取れたらいい身としてはありがたい気もしますが、結局[何をさせたいか](http://samacoba.hatenablog.com/entry/2018/07/18/115141)という問題にもどってきそうな感じもします。

※2019年3月27日  
https://github.com/samacoba/ObjectCounter/blob/master/docs/doc001.md  
より過去の記事のバックアップ用に転記
